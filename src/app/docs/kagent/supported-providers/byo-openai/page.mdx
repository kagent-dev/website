---
title: "BYO OpenAI-compatible model"
pageOrder: 8
description: "Bring your own OpenAI-compatible model to kagent."
---

export const metadata = {
  title: "BYO OpenAI-compatible model",
  description: "Bring your own OpenAI-compatible model to kagent.",
  author: "kagent.dev"
};

# BYO OpenAI-compatible model

You can bring your own model from an [OpenAI API-compatible](https://platform.openai.com/docs/api-reference/introduction) LLM provider. The example integrates with [Cohere AI](https://cohere.com/).

1. Save your API key from the OpenAI-compatible provider as an environment variable. For example, navigate to the [Cohere AI dashboard](https://dashboard.cohere.com/api-keys).

   ```bash
   export PROVIDER_API_KEY=Dgs...
   ```

2. Create a Kubernetes secret that stores your API key. Make sure to create the secret in the same namespace as you plan to create your agent, such as `kagent`.

   ```bash
   kubectl create secret generic kagent-my-provider -n kagent --from-literal PROVIDER_API_KEY=$PROVIDER_API_KEY
   ```

3. Create a ModelConfig resource.

   ```yaml
   kubectl apply -f - <<EOF
   apiVersion: kagent.dev/v1alpha2
   kind: ModelConfig
   metadata:
     name: my-provider-config
     namespace: kagent
   spec:
     apiKeySecret: kagent-my-provider
     apiKeySecretKey: PROVIDER_API_KEY
     model: command-a-03-2025
     provider: OpenAI
     openAI:
       baseUrl: "https://api.cohere.ai/compatibility/v1"
   EOF
   ```

   Review the following table to understand this configuration. For more information, see the [API docs](https://kagent.dev/docs/kagent/resources/api-ref#openaiconfig).

   | Setting | Description |
   | --- | --- |
   | `apiKeySecret` | The name of the Kubernetes secret that stores your API key. |
   | `apiKeySecretKey` | The key in the secret that stores your API key. |
   | `model` | The OpenAI API-compatible model to use. For more information about the model, consult your LLM provider's documentation. For example, you might use `command-a-03-2025` for [Cohere AI](https://docs.cohere.com/v1/docs/models). |
   | `provider` | To use an OpenAI API-compatible model, set the provider to `OpenAI`. |
   | `openAI` | Additional provider details. For available settings, consult your LLM provider's documentation. At the least, you must configure the `baseUrl` setting to point to the endpoint of your LLM provider. |
   | `baseUrl` | The base URL of your LLM provider. Note that the LLM provider might have a special base URL for OpenAI compatibility, such as `"https://api.cohere.ai/compatibility/v1"` for [Cohere AI](https://cohere.com/). |

Good job! You added a model to kagent. Next, you can [create or update an agent](https://kagent.dev/docs/kagent/getting-started/first-agent) to use this model.

## TLS Configuration

kagent supports TLS CA configuration for `ModelConfig`s to enable secure communication with LLMs using custom certificates. This feature allows for `Agent`s to communicate with an LLM using custom certificates, which is useful for internal or company-managed LLM servers.

**Note:** TLS configuration only supports OpenAI-compatible providers.

### Use Case: Custom CA Certificates

When your LLM server uses custom certificates (for example, internal or company certificates), you'll need to configure the CA certificate in your `ModelConfig`.

1. You'll need a `Secret` containing the relevant CA certificate. For example, you could create a Kubernetes secret that stores the certificate.

   ```bash
   kubectl -n kagent create secret generic llm-certs \
     --from-file=ca.crt=ca.crt
   ```
   
   **Note:** The secret must be created in the same namespace as your `ModelConfig`.

2. Create a `ModelConfig` resource with TLS configuration that references the CA certificate `Secret`.

   ```yaml
   apiVersion: kagent.dev/v1alpha2
   kind: ModelConfig
   metadata:
     name: internal-llm-model-config
     namespace: kagent
   spec:
     apiKeySecret: llm-secret
     apiKeySecretKey: api-key
     provider: OpenAI
     model: ${MODEL_NAME}
     openAI:
       baseUrl: ${COMPATIBLE_PROVIDER_URL}
     tls:
       caCertSecretRef: llm-certs
       caCertSecretKey: ca.crt
   ```

### Use Case: Insecure Communication

> **Warning:** This configuration should **only** be used for demo purposes. It is not intended for production use.

For development or testing scenarios where you need to disable TLS verification, you can configure the `ModelConfig` to skip certificate verification.

```yaml
apiVersion: kagent.dev/v1alpha2
kind: ModelConfig
metadata:
  name: internal-llm-model-config
  namespace: kagent
spec:
  apiKeySecret: llm-secret
  apiKeySecretKey: api-key
  provider: OpenAI
  model: ${MODEL_NAME}
  openAI:
    baseUrl: ${COMPATIBLE_PROVIDER_URL}
  tls:
    disableVerify: true
```

### TLS Configuration Settings

Review the following table to understand the TLS configuration options. For more information, see the [API docs](https://kagent.dev/docs/kagent/resources/api-ref#modelconfigspec).

| Setting | Description |
| --- | --- |
| `tls.caCertSecretRef` | The name of the Kubernetes secret that contains the CA certificate. The secret must be in the same namespace as the `ModelConfig`. |
| `tls.caCertSecretKey` | The key in the secret that stores the CA certificate file. |
| `tls.disableVerify` | When set to `true`, disables TLS certificate verification. **Warning:** Only use this for demo purposes, not in production. |
